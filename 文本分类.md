# 文本分类

#### 读取数据


```python
from fastNLP.io import ChnSentiCorpLoader
loader = ChnSentiCorpLoader() 
data_dir = loader.download()   
data_bundle = loader.load(data_dir) 
```


```python
print(data_bundle)
```

    In total 3 datasets:
    	train has 9600 instances.
    	dev has 1200 instances.
    	test has 1200 instances.
    



```python
print(data_bundle.get_dataset('train')[:2])
```

    +---------------------------+--------+
    | raw_chars                 | target |
    +---------------------------+--------+
    | 选择珠江花园的原因就是... | 1      |
    | 15.4寸笔记本的键盘确实... | 1      |
    +---------------------------+--------+


#### 预处理数据


```python
from fastNLP.io import ChnSentiCorpPipe

pipe = ChnSentiCorpPipe()
data_bundle = pipe.process(data_bundle)

print(data_bundle)
```

    In total 3 datasets:
    	train has 9600 instances.
    	dev has 1200 instances.
    	test has 1200 instances.
    In total 2 vocabs:
    	chars has 4409 entries.
    	target has 2 entries.
    



```python
print(data_bundle.get_dataset('train')[:5])
```

    +-----------------+--------+----------------+---------+
    | raw_chars       | target | chars          | seq_len |
    +-----------------+--------+----------------+---------+
    | 选择珠江花园... | 0      | [338, 464, ... | 106     |
    | 15.4寸笔记本... | 0      | [50, 133, 2... | 56      |
    | 房间太小。其... | 1      | [30, 28, 72... | 20      |
    | 1.接电源没有... | 1      | [50, 20, 19... | 64      |
    | 今天才知道这... | 0      | [554, 77, 1... | 70      |
    +-----------------+--------+----------------+---------+



```python
char_vocab = data_bundle.get_vocab('chars')
print(char_vocab)
```

    Vocabulary(['选', '择', '珠', '江', '花']...)



```python
index = char_vocab.to_index('选')
print("'选'的index是{}".format(index))
print("index:{}对应的汉字是{}".format(index, char_vocab.to_word(index)))
```

    '选'的index是338
    index:338对应的汉字是选


#### 选择预训练词向量


```python
from fastNLP.embeddings import StaticEmbedding

word2vec_embed = StaticEmbedding(char_vocab, model_dir_or_name='cn-char-fastnlp-100d')
```

      8%|▊         | 311k/3.70M [00:00<00:01, 3.09MB/s]

    http://212.129.155.247/embedding/cn_char_fastnlp_100d.zip not found in cache, downloading to /var/folders/mp/f9d45_9n36gfb66q6l9_wqvr0000gn/T/tmpxja7of2w


    100%|██████████| 3.70M/3.70M [00:00<00:00, 3.77MB/s]


    Finish download from http://212.129.155.247/embedding/cn_char_fastnlp_100d.zip
    Copy file to /Users/ryh/.fastNLP/embedding/cn_char_fastnlp_100d
    Found 4321 out of 4409 words in the pre-training embedding.


#### 创建模型


```python
from torch import nn
from fastNLP.modules import LSTM
import torch

# 定义模型
class BiLSTMMaxPoolCls(nn.Module):
    def __init__(self, embed, num_classes, hidden_size=400, num_layers=1, dropout=0.3):
        super().__init__()
        self.embed = embed

        self.lstm = LSTM(self.embed.embedding_dim, hidden_size=hidden_size//2, num_layers=num_layers,
                         batch_first=True, bidirectional=True)
        self.dropout_layer = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, chars, seq_len):  # 这里的名称必须和DataSet中相应的field对应，比如之前我们DataSet中有chars，这里就必须为chars
        # chars:[batch_size, max_len]
        # seq_len: [batch_size, ]
        chars = self.embed(chars)
        outputs, _ = self.lstm(chars, seq_len)
        outputs = self.dropout_layer(outputs)
        outputs, _ = torch.max(outputs, dim=1)
        outputs = self.fc(outputs)

        return {'pred':outputs}  # [batch_size,], 返回值必须是dict类型，且预测值的key建议设为pred

# 初始化模型
model = BiLSTMMaxPoolCls(word2vec_embed, len(data_bundle.get_vocab('target')))
```

#### 训练模型


```python
from fastNLP import Trainer
from fastNLP import CrossEntropyLoss
from torch.optim import Adam
from fastNLP import AccuracyMetric

loss = CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=0.001)
metric = AccuracyMetric()
device = 0 if torch.cuda.is_available() else 'cpu'  # 如果有gpu的话在gpu上运行，训练速度会更快

trainer = Trainer(train_data=data_bundle.get_dataset('train'), model=model, loss=loss,
                  optimizer=optimizer, batch_size=32, dev_data=data_bundle.get_dataset('dev'),
                  metrics=metric, device=device)
trainer.train()  # 开始训练，训练完成之后默认会加载在dev上表现最好的模型

# 在测试集上测试一下模型的性能
from fastNLP import Tester
print("Performance on test is:")
tester = Tester(data=data_bundle.get_dataset('test'), model=model, metrics=metric, batch_size=64, device=device)
tester.test()
```

    input fields after batch(if batch size is 2):
    	target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) 
    	chars: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 106]) 
    	seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) 
    target fields after batch(if batch size is 2):
    	target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) 
    
    training epochs started 2019-10-24-19-31-44



    HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=3000), HTML(value='')), layout=Layout(display…


    Performance on test is:



    HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=19), HTML(value='')), layout=Layout(display='…


    Evaluate data in 6.45 seconds!
    [tester] 
    AccuracyMetric: acc=0.495





    {'AccuracyMetric': {'acc': 0.495}}


